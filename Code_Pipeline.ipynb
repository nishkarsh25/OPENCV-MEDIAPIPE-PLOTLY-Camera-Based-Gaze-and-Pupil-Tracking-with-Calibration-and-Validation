{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57c155c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Chessboard settings (adjust based on your board)\n",
    "chessboard_size = (10, 7)  # 11x8 chessboard dimensions\n",
    "square_size = 25  # in mm (for real-world scale, optional)\n",
    "\n",
    "# Prepare object points (3D)\n",
    "objp = np.zeros((np.prod(chessboard_size), 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:chessboard_size[0], 0:chessboard_size[1]].T.reshape(-1, 2) * square_size\n",
    "\n",
    "objpoints = []  # 3D world points\n",
    "imgpoints = []  # 2D image points\n",
    "\n",
    "# Load calibration images\n",
    "images = glob.glob(\"Calibration_Images/*.jpg\")  # Only JPG  # Match all files # Path to saved images\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, chessboard_size, None)\n",
    "\n",
    "    if ret:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and show corners\n",
    "        cv2.drawChessboardCorners(img, chessboard_size, corners, ret)\n",
    "        cv2.imshow('Corners', img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Camera Calibration\n",
    "ret, camera_matrix, dist_coeffs, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "# Save calibration results\n",
    "np.savez(\"camera_calibration.npz\", camera_matrix=camera_matrix, dist_coeffs=dist_coeffs)\n",
    "\n",
    "print(\"Camera Matrix:\\n\", camera_matrix)\n",
    "print(\"Distortion Coefficients:\\n\", dist_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c9ee8e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "total_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], camera_matrix, dist_coeffs)\n",
    "    error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2) / len(imgpoints2)\n",
    "    total_error += error\n",
    "print(\"Mean Reprojection Error:\", total_error / len(objpoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac5839d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load camera calibration parameters\n",
    "calibration_data = np.load(\"camera_calibration.npz\")\n",
    "camera_matrix = calibration_data[\"camera_matrix\"]\n",
    "dist_coeffs = calibration_data[\"dist_coeffs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e64bd1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define folder name\n",
    "frame_save_path = \"captured_frames_IONI\"\n",
    "\n",
    "# Delete the folder if it exists and create a new one\n",
    "if os.path.exists(frame_save_path):\n",
    "    shutil.rmtree(frame_save_path)\n",
    "\n",
    "os.makedirs(frame_save_path)\n",
    "\n",
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=False,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# Eye landmark indices (MediaPipe 468-face model)\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]  # Left eye landmarks\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]  # Right eye landmarks\n",
    "\n",
    "# Eye aspect ratio (EAR) threshold for blink detection\n",
    "EAR_THRESHOLD = 0.18  # Lowered threshold for better sensitivity\n",
    "BLINK_CONSECUTIVE_FRAMES = 2  # Fewer frames to confirm a blink\n",
    "\n",
    "# Variables for blink detection\n",
    "left_eye_closed = False\n",
    "right_eye_closed = False\n",
    "left_eye_counter = 0\n",
    "right_eye_counter = 0\n",
    "\n",
    "# Data storage for graphs\n",
    "gaze_data = []  # Stores gaze direction (x, y)\n",
    "frame_numbers = []  # Stores frame numbers\n",
    "all_dilation_data = []  # Stores pupil sizes over time\n",
    "all_frame_numbers = []  # Stores corresponding frame numbers\n",
    "left_pupil_coords = []  # Stores left pupil coordinates\n",
    "right_pupil_coords = []  # Stores right pupil coordinates\n",
    "left_blink_frames = []  # Stores frames where left eye blinks\n",
    "right_blink_frames = []  # Stores frames where right eye blinks\n",
    "both_blink_frames = []  # Stores frames where both eyes blink\n",
    "\n",
    "# Gaze direction classification (8 classes)\n",
    "DIRECTIONS_8 = [\"Right\", \"Top-Right\", \"Top\", \"Top-Left\", \"Left\", \"Bottom-Left\", \"Bottom\", \"Bottom-Right\"]\n",
    "\n",
    "def normalized_to_pixel_coords(landmark, image_width, image_height):\n",
    "    \"\"\"Convert normalized landmark coordinates to pixel values\"\"\"\n",
    "    return int(landmark.x * image_width), int(landmark.y * image_height)\n",
    "\n",
    "def extract_eye_region(frame, eye_landmarks):\n",
    "    \"\"\"Crop the eye region from the frame\"\"\"\n",
    "    mask = np.zeros_like(frame[:, :, 0])\n",
    "    points = np.array([normalized_to_pixel_coords(l, frame.shape[1], frame.shape[0]) for l in eye_landmarks])\n",
    "\n",
    "    cv2.fillPoly(mask, [points], 255)\n",
    "    eye = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(points)\n",
    "    eye_cropped = eye[y:y+h, x:x+w]\n",
    "\n",
    "    return eye_cropped, x, y, w, h\n",
    "\n",
    "def detect_pupil(eye):\n",
    "    \"\"\"Detect the pupil using adaptive thresholding, contour detection, and Hough Circles\"\"\"\n",
    "    if eye is None or eye.size == 0:\n",
    "        return None, None, None\n",
    "    # Convert to grayscale and enhance contrast\n",
    "    gray = cv2.cvtColor(eye, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "\n",
    "    # Adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2\n",
    "    )\n",
    "\n",
    "    # Morphological operations to remove noise\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Filter contours by size\n",
    "        contours = [c for c in contours if 100 < cv2.contourArea(c) < 5000]\n",
    "\n",
    "        if contours:\n",
    "            # Find the largest contour\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "            # Fit an ellipse to the largest contour\n",
    "            if len(largest_contour) >= 5:\n",
    "                ellipse = cv2.fitEllipse(largest_contour)\n",
    "                (px, py), (MA, ma), angle = ellipse\n",
    "                radius = (MA + ma) / 4  # Approximate radius from major/minor axis\n",
    "                return int(px), int(py), int(radius)\n",
    "\n",
    "    # Fallback: Use Hough Circles if contour detection fails\n",
    "    circles = cv2.HoughCircles(\n",
    "        blurred,\n",
    "        cv2.HOUGH_GRADIENT,\n",
    "        dp=1,\n",
    "        minDist=50,\n",
    "        param1=50,\n",
    "        param2=30,\n",
    "        minRadius=10,\n",
    "        maxRadius=50\n",
    "    )\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        for circle in circles[0, :]:\n",
    "            px, py, radius = circle[0], circle[1], circle[2]\n",
    "            return px, py, radius\n",
    "\n",
    "    return None, None, None\n",
    "\n",
    "def eye_aspect_ratio(eye_landmarks):\n",
    "    \"\"\"Calculate the eye aspect ratio (EAR) to detect blinks\"\"\"\n",
    "    # Extract landmark coordinates\n",
    "    points = np.array([(lm.x, lm.y) for lm in eye_landmarks])\n",
    "\n",
    "    # Compute the Euclidean distances between the vertical eye landmarks\n",
    "    A = np.linalg.norm(points[1] - points[5])\n",
    "    B = np.linalg.norm(points[2] - points[4])\n",
    "\n",
    "    # Compute the Euclidean distance between the horizontal eye landmarks\n",
    "    C = np.linalg.norm(points[0] - points[3])\n",
    "\n",
    "    # Calculate the EAR\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "def normalize_gaze_vector(gaze_vector):\n",
    "    \"\"\"Normalize the gaze vector to a unit vector.\"\"\"\n",
    "    magnitude = np.linalg.norm(gaze_vector)\n",
    "    if magnitude == 0:\n",
    "        return gaze_vector  # Avoid division by zero\n",
    "    return gaze_vector / magnitude\n",
    "\n",
    "def classify_gaze_direction(gaze_vector):\n",
    "    \"\"\"Classify gaze direction into 8 classes based on the angle of the gaze vector.\"\"\"\n",
    "    angle = np.arctan2(gaze_vector[1], gaze_vector[0])  # Angle in radians\n",
    "    angle_deg = np.degrees(angle) % 360  # Convert to degrees and normalize to [0, 360)\n",
    "\n",
    "    # Define angle ranges for 8 directions\n",
    "    if 337.5 <= angle_deg or angle_deg < 22.5:\n",
    "        return \"Right\"\n",
    "    elif 22.5 <= angle_deg < 67.5:\n",
    "        return \"Top-Right\"\n",
    "    elif 67.5 <= angle_deg < 112.5:\n",
    "        return \"Top\"\n",
    "    elif 112.5 <= angle_deg < 157.5:\n",
    "        return \"Top-Left\"\n",
    "    elif 157.5 <= angle_deg < 202.5:\n",
    "        return \"Left\"\n",
    "    elif 202.5 <= angle_deg < 247.5:\n",
    "        return \"Bottom-Left\"\n",
    "    elif 247.5 <= angle_deg < 292.5:\n",
    "        return \"Bottom\"\n",
    "    elif 292.5 <= angle_deg < 337.5:\n",
    "        return \"Bottom-Right\"\n",
    "    \n",
    "\n",
    "def get_red_cross_position(frame_count, frame_width, frame_height, speed=10, padding=50):\n",
    "    \"\"\"\n",
    "    Calculate the position of the red cross based on the frame count.\n",
    "    The cross moves in a rectangular path along the border of the screen with equal padding.\n",
    "    Ensures the cross stays within the padded area.\n",
    "    \"\"\"\n",
    "    # Calculate the dimensions of the inner rectangle\n",
    "    inner_width = frame_width - 2 * padding\n",
    "    inner_height = frame_height - 2 * padding\n",
    "\n",
    "    # Total perimeter of the inner rectangle\n",
    "    perimeter = 2 * (inner_width + inner_height)\n",
    "\n",
    "    # Distance traveled by the cross\n",
    "    distance = (frame_count * speed) % perimeter\n",
    "\n",
    "    # Calculate the position of the red cross\n",
    "    if distance < inner_width:\n",
    "        # Moving along the top edge (with padding)\n",
    "        x = padding + distance\n",
    "        y = padding\n",
    "    elif distance < inner_width + inner_height:\n",
    "        # Moving along the right edge (with padding)\n",
    "        x = frame_width - padding - 1\n",
    "        y = padding + (distance - inner_width)\n",
    "    elif distance < 2 * inner_width + inner_height:\n",
    "        # Moving along the bottom edge (with padding)\n",
    "        x = padding + (inner_width - (distance - (inner_width + inner_height)))\n",
    "        y = frame_height - padding - 1\n",
    "    else:\n",
    "        # Moving along the left edge (with padding)\n",
    "        x = padding\n",
    "        y = padding + (inner_height - (distance - (2 * inner_width + inner_height)))\n",
    "\n",
    "    # Clamp the coordinates to ensure they stay within the padded area\n",
    "    x = max(padding, min(x, frame_width - padding - 1))\n",
    "    y = max(padding, min(y, frame_height - padding - 1))\n",
    "\n",
    "    return int(x), int(y)\n",
    "\n",
    "# Start Video Capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "\n",
    "# Get actual frame width & height\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(f\"Using Webcam Resolution: {frame_width}x{frame_height}\")\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.undistort(frame, camera_matrix, dist_coeffs)\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    # Get the position of the red cross\n",
    "    red_cross_x, red_cross_y = get_red_cross_position(frame_count, frame_width, frame_height, speed=10, padding=40)\n",
    "\n",
    "    # Draw the red cross on the frame\n",
    "    cross_size = 20  # Size of the cross\n",
    "    cv2.line(frame, (red_cross_x - cross_size, red_cross_y), (red_cross_x + cross_size, red_cross_y), (0, 0, 255), 2)\n",
    "    cv2.line(frame, (red_cross_x, red_cross_y - cross_size), (red_cross_x, red_cross_y + cross_size), (0, 0, 255), 2)\n",
    "\n",
    "    text_x, text_y = 50, 50  # Shift text to top\n",
    "\n",
    "    cv2.putText(frame, \"Gaze & Pupil Tracking\", (text_x, text_y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        face_landmarks = results.multi_face_landmarks[0]\n",
    "\n",
    "        left_eye = [face_landmarks.landmark[i] for i in LEFT_EYE]\n",
    "        right_eye = [face_landmarks.landmark[i] for i in RIGHT_EYE]\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "       \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57c155c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Chessboard settings (adjust based on your board)\n",
    "chessboard_size = (10, 7)  # 11x8 chessboard dimensions\n",
    "square_size = 25  # in mm (for real-world scale, optional)\n",
    "\n",
    "# Prepare object points (3D)\n",
    "objp = np.zeros((np.prod(chessboard_size), 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:chessboard_size[0], 0:chessboard_size[1]].T.reshape(-1, 2) * square_size\n",
    "\n",
    "objpoints = []  # 3D world points\n",
    "imgpoints = []  # 2D image points\n",
    "\n",
    "# Load calibration images\n",
    "images = glob.glob(\"Calibration_Images/*.jpg\")  # Only JPG  # Match all files # Path to saved images\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, chessboard_size, None)\n",
    "\n",
    "    if ret:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and show corners\n",
    "        cv2.drawChessboardCorners(img, chessboard_size, corners, ret)\n",
    "        cv2.imshow('Corners', img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Camera Calibration\n",
    "ret, camera_matrix, dist_coeffs, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "# Save calibration results\n",
    "np.savez(\"camera_calibration.npz\", camera_matrix=camera_matrix, dist_coeffs=dist_coeffs)\n",
    "\n",
    "print(\"Camera Matrix:\\n\", camera_matrix)\n",
    "print(\"Distortion Coefficients:\\n\", dist_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c9ee8e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "total_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], camera_matrix, dist_coeffs)\n",
    "    error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2) / len(imgpoints2)\n",
    "    total_error += error\n",
    "print(\"Mean Reprojection Error:\", total_error / len(objpoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac5839d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load camera calibration parameters\n",
    "calibration_data = np.load(\"camera_calibration.npz\")\n",
    "camera_matrix = calibration_data[\"camera_matrix\"]\n",
    "dist_coeffs = calibration_data[\"dist_coeffs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e64bd1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define folder name\n",
    "frame_save_path = \"captured_frames_IONI\"\n",
    "\n",
    "# Delete the folder if it exists and create a new one\n",
    "if os.path.exists(frame_save_path):\n",
    "    shutil.rmtree(frame_save_path)\n",
    "\n",
    "os.makedirs(frame_save_path)\n",
    "\n",
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=False,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# Eye landmark indices (MediaPipe 468-face model)\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]  # Left eye landmarks\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]  # Right eye landmarks\n",
    "\n",
    "# Eye aspect ratio (EAR) threshold for blink detection\n",
    "EAR_THRESHOLD = 0.18  # Lowered threshold for better sensitivity\n",
    "BLINK_CONSECUTIVE_FRAMES = 2  # Fewer frames to confirm a blink\n",
    "\n",
    "# Variables for blink detection\n",
    "left_eye_closed = False\n",
    "right_eye_closed = False\n",
    "left_eye_counter = 0\n",
    "right_eye_counter = 0\n",
    "\n",
    "# Data storage for graphs\n",
    "gaze_data = []  # Stores gaze direction (x, y)\n",
    "frame_numbers = []  # Stores frame numbers\n",
    "all_dilation_data = []  # Stores pupil sizes over time\n",
    "all_frame_numbers = []  # Stores corresponding frame numbers\n",
    "left_pupil_coords = []  # Stores left pupil coordinates\n",
    "right_pupil_coords = []  # Stores right pupil coordinates\n",
    "left_blink_frames = []  # Stores frames where left eye blinks\n",
    "right_blink_frames = []  # Stores frames where right eye blinks\n",
    "both_blink_frames = []  # Stores frames where both eyes blink\n",
    "\n",
    "# Gaze direction classification (8 classes)\n",
    "DIRECTIONS_8 = [\"Right\", \"Top-Right\", \"Top\", \"Top-Left\", \"Left\", \"Bottom-Left\", \"Bottom\", \"Bottom-Right\"]\n",
    "\n",
    "def normalized_to_pixel_coords(landmark, image_width, image_height):\n",
    "    \"\"\"Convert normalized landmark coordinates to pixel values\"\"\"\n",
    "    return int(landmark.x * image_width), int(landmark.y * image_height)\n",
    "\n",
    "def extract_eye_region(frame, eye_landmarks):\n",
    "    \"\"\"Crop the eye region from the frame\"\"\"\n",
    "    mask = np.zeros_like(frame[:, :, 0])\n",
    "    points = np.array([normalized_to_pixel_coords(l, frame.shape[1], frame.shape[0]) for l in eye_landmarks])\n",
    "\n",
    "    cv2.fillPoly(mask, [points], 255)\n",
    "    eye = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(points)\n",
    "    eye_cropped = eye[y:y+h, x:x+w]\n",
    "\n",
    "    return eye_cropped, x, y, w, h\n",
    "\n",
    "def detect_pupil(eye):\n",
    "    \"\"\"Detect the pupil using adaptive thresholding, contour detection, and Hough Circles\"\"\"\n",
    "    if eye is None or eye.size == 0:\n",
    "        return None, None, None\n",
    "    # Convert to grayscale and enhance contrast\n",
    "    gray = cv2.cvtColor(eye, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "\n",
    "    # Adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2\n",
    "    )\n",
    "\n",
    "    # Morphological operations to remove noise\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Filter contours by size\n",
    "        contours = [c for c in contours if 100 < cv2.contourArea(c) < 5000]\n",
    "\n",
    "        if contours:\n",
    "            # Find the largest contour\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "            # Fit an ellipse to the largest contour\n",
    "            if len(largest_contour) >= 5:\n",
    "                ellipse = cv2.fitEllipse(largest_contour)\n",
    "                (px, py), (MA, ma), angle = ellipse\n",
    "                radius = (MA + ma) / 4  # Approximate radius from major/minor axis\n",
    "                return int(px), int(py), int(radius)\n",
    "\n",
    "    # Fallback: Use Hough Circles if contour detection fails\n",
    "    circles = cv2.HoughCircles(\n",
    "        blurred,\n",
    "        cv2.HOUGH_GRADIENT,\n",
    "        dp=1,\n",
    "        minDist=50,\n",
    "        param1=50,\n",
    "        param2=30,\n",
    "        minRadius=10,\n",
    "        maxRadius=50\n",
    "    )\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        for circle in circles[0, :]:\n",
    "            px, py, radius = circle[0], circle[1], circle[2]\n",
    "            return px, py, radius\n",
    "\n",
    "    return None, None, None\n",
    "\n",
    "def eye_aspect_ratio(eye_landmarks):\n",
    "    \"\"\"Calculate the eye aspect ratio (EAR) to detect blinks\"\"\"\n",
    "    # Extract landmark coordinates\n",
    "    points = np.array([(lm.x, lm.y) for lm in eye_landmarks])\n",
    "\n",
    "    \n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
